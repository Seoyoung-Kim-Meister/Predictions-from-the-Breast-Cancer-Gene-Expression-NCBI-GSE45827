{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3940a39a-018d-4e25-8c65-7fd324a20c93",
   "metadata": {},
   "source": [
    "This notebook ```beyond_baseline.ipynb``` is to fine-tune the model using AdamW optimizer to improve accuracy and loss, and eventually to overcome the baseline accuracy. For more information on data and structure, please refer to ```predictions.ipynb``` in this repository.\n",
    "\n",
    "\n",
    "# Advanced Fine-Tuning: Optimizing Accuracy with AdamW\n",
    "## Overview\n",
    "\n",
    "This notebook serves as a dedicated implementation guide for tuning the AdamW (Adaptive Moments with Weight Decay) optimizer. It is designed as a direct follow-up to our initial model development phase.\n",
    "\n",
    "The Goal: Move beyond \"standard\" training (SGD, Adam, adding ReLU) results by precisely calibrating the optimizer to improve validation accuracy, stabilize loss convergence, and prevent over-fitting during the fine-tuning process.\n",
    "\n",
    "## Why AdamW for fine-tuning?\n",
    "\n",
    "While standard Adam is effective, AdamW decouples weight decay from the gradient update. This is critical during fine-tuning because:\n",
    "\n",
    "Weight Decay Recovery: It restores the original intent of $L_2$ regularization.\n",
    "\n",
    "Generalization: It helps the model maintain the knowledge of pre-trained weights while adapting to new data.\n",
    "\n",
    "Convergence: It often leads to lower final loss and higher accuracy compared to standard Adam when hyperparameters are properly tuned.\n",
    "\n",
    "\n",
    "## Quick Summary: Why \"Shallow-learning\" with a single layer wins in genomics\n",
    "\n",
    "The \"Small N, Large P\" Problem: You have ~30,000 features but only ~150 patients. A deep model has so many parameters that it will simply \"memorize\" your specific patients (like a lookup table) rather than learning actual biology. In other words, a deep model is prone to overfitting.\n",
    "\n",
    "Additive Biology: In computer vision, pixels must form edges, then shapes, then objects. This needs many layers. In genomics, the relationship is often direct and additive: a specific set of genes being \"on\" or \"off\" directly signals a tumor. A single hidden layer captures this perfectly; adding more layers just adds noise.\n",
    "\n",
    "The Curse of Dimensionality: In 30,000~dimensional space, data points are very spread out. It is mathematically easy to separate them with a single straight \"wall\" (a hyperplane). Shallow networks find these clean, straight boundaries. Deep networks try to \"twist\" the space, which usually results in a model that works on your data but fails on any new patient. Again, there is more possibility to overfit.\n",
    "\n",
    "Signal vs. Noise: Biological data is very \"noisy.\" Every extra layer in a neural network acts like a megaphone for that noise. A Shallow Network acts as a bottleneck, forcing the model to ignore the thousands of irrelevant genes and focus only on the strong biological signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4eea0d7-59e3-404f-b2b0-407600065d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The learning tends to be better with fastai\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c257ed-d82c-4ad6-ac01-92fd32b3775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3a4112-5f4b-4237-b8d8-1f0f4f5c5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl, certifi\n",
    "ssl._create_default_https_context = lambda *args, **kwargs: ssl.create_default_context(cafile=certifi.where())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a420a6-4642-45fd-9642-6c8219eaf077",
   "metadata": {},
   "source": [
    "# Recall: Data from patients with primary invasive breast cancer\n",
    "This study examined tissue samples from patients with primary invasive breast cancer, including four major tumor subtypes: triple-negative (TN) (41 cases), HER2-positive (30 cases), luminal A (29 cases), and luminal B (30 cases). ***RNA, the molecule that reflects which genes are active in a cell, was extracted from all samples***. Gene activity across the entire genome was then measured using Affymetrix U133 Plus 2.0 microarray technology.\n",
    "\n",
    "| Sample type   | Purpose                                            |\n",
    "| ------------- | -------------------------------------------------- |\n",
    "| Tumors        | Define subtype-specific cancer expression profiles |\n",
    "| Normal tissue | Identify cancer-specific changes                   |\n",
    "| Cell lines    | Enable experimental follow-up and model validation |\n",
    "\n",
    "\n",
    "We obtained the data from National Institutes of Health (NIH), the National Center for Biotechnology Information, which is available at https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE45827."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2b53c6-e129-4c5f-bf9f-51cdea07eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE45nnn/GSE45827/matrix/GSE45827_series_matrix.txt.gz\"\n",
    "path = Path(\"GSE45827_series_matrix.txt.gz\")      # make sure that the file is saved in the same directory.\n",
    "\n",
    "if not path.exists():\n",
    "   urllib.request.urlretrieve(url, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68cdf5f-3519-4a9c-9f57-e7401d737150",
   "metadata": {},
   "source": [
    "# Data format from NCBI GEO\n",
    "Data format: *NCBI GEO (Gene Expression Omnibus)*\n",
    "\n",
    "File type: Series Matrix\n",
    "\n",
    "We follow the NCBI GEO data format below: *\"!series_matrix_table_begin\"* (respectively, *\"!series_matrix_table_end\"*) is a standard marker defined by NCBI GEO, used in GEO Series Matrix files (*_series_matrix.txt) to mark the beginning of the expression data table.\n",
    "\n",
    "We import the data directly from the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b1d558-93fa-4033-8cf2-f3fac7d4881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path, \"rt\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Find where expression data starts\n",
    "start = [i for i, l in enumerate(lines) if l.startswith(\"!series_matrix_table_begin\")][0] + 1\n",
    "end = [i for i, l in enumerate(lines) if l.startswith(\"!series_matrix_table_end\")][0]\n",
    "\n",
    "# \"\\t\" for tab-separated data table\n",
    "data = pd.read_csv(\n",
    "    path,\n",
    "    sep=\"\\t\",\n",
    "    skiprows=start,\n",
    "    nrows=end - start\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ccdb3-9d76-4493-b06f-59aedaf023e3",
   "metadata": {},
   "source": [
    "# A suitable data frame\n",
    "We use 'data.set_index(data.columns[0])' and return a new DataFrame (see the table below). After transpose, the first column of X is the sample ID (e.g., GSM1116084, GSM1116085, etc.) and the first row is the probe IDs (e.g., 1007_s_at, 1053_at, etc.). Probe IDs are identifiers for the physical DNA probes to detect gene expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7123ae41-124d-4ac8-ac8b-8462f5a3716c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 29874)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First column is gene ID.\n",
    "data = data.set_index(data.columns[0])\n",
    "\n",
    "# Transpose: samples × genes\n",
    "X = data.T\n",
    "\n",
    "# number of (samples x genes) \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeecb3d-9447-412e-bf43-5d3fed33d30a",
   "metadata": {},
   "source": [
    "The values of the table for given sample IDs and probe IDs represent gene-expression level — specifically, normalized microarray signal intensities measured by each probe for each sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eea16-2fa5-4d6d-94e2-b7958f995fac",
   "metadata": {},
   "source": [
    "# Labels for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5deed65d-6b28-4206-bcbe-cc1333bebd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract phenotype lines\n",
    "pheno_lines = [l for l in lines if l.startswith(\"!Sample_source_name_ch1\")]\n",
    "\n",
    "labels = []\n",
    "for line in pheno_lines:\n",
    "    parts = line.strip().split(\"\\t\")[1:]\n",
    "    labels = parts\n",
    "    \n",
    "# In total there are 155 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7bde529-7dce-4c89-8661-b68bc9cb216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = pd.Series(labels)\n",
    "\n",
    "# Returns 1=true if the label contains 'tumor' and returns 0=false otherwise\n",
    "y = pd.Series(labels).str.lower().str.contains(\"tumor\").astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb83504-1ead-4301-a174-d5ba57644429",
   "metadata": {},
   "source": [
    "As it shows above, there are 6 distinct labels: \"Human Basal Tumor Sample\", \"Human CellLine\", \"Human Her2 Tumor Sample\", \"Human Luminal A Tumor Sample\", \"Human Luminal B Tumor Sample\", \"Human Normal\". Now we assign boolean value to the labels which contain the word \"tumor\" to train the machine to study to give the right conclusions matching with the label. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85eff0-653e-4612-afe1-2bbc86b10528",
   "metadata": {},
   "source": [
    "# Steps from ```predictions.ipynb```.\n",
    "## Basic set-up for learning using two different methods: Stochastic gradient descent(SGD) and Adam optimizer.\n",
    "\n",
    "Now we convert to torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470ab5df-5415-4d8b-81b3-952f7174d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# X is a pandas DataFrame here\n",
    "X_df = X.copy()\n",
    "\n",
    "X_df = (X_df - X_df.mean(axis=0)) / X_df.std(axis=0)\n",
    "X_df = X_df.fillna(0.0)\n",
    "\n",
    "# now convert to torch\n",
    "X = torch.tensor(X_df.values, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63c0aaa6-4836-4b6a-84fc-1efde3d882dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X)\n",
    "# The function randperm(n) generates a random ordering of integers from 1 to n\n",
    "idx = torch.randperm(n)\n",
    "\n",
    "train_idx = idx[:int(0.8*n)]\n",
    "valid_idx = idx[int(0.8*n):]\n",
    "\n",
    "train_x, train_y = X[train_idx], y[train_idx]\n",
    "valid_x, valid_y = X[valid_idx], y[valid_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56bf485-3d52-49d5-a00a-2dde47dc2f9b",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f8544e-1a5b-44bc-8fed-b225c848fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use sklearn for PCA and modify the PyTorch tensor to the right format to use sklearn\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# What is n_components in PCA? How can we choose optimal n_components?\n",
    "\n",
    "pca = PCA(n_components=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdde3513-00a9-489b-9343-a20851b64e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.0765045e+01, -2.4614185e+01, -2.7316547e+01, ...,  3.6811919e+00, -1.8935709e+01, -1.5399693e+01],\n",
       "       [-4.2143887e+01, -2.5798975e+01,  8.5787735e+01, ...,  6.0338507e+00,  1.4269685e+00,  1.3738943e+01],\n",
       "       [-1.5060004e+02,  8.3600174e+01, -8.5271500e+01, ...,  9.2324817e-01, -1.1091703e+00,  2.0955551e+00],\n",
       "       ...,\n",
       "       [ 3.6703491e+01, -2.6457605e+01,  1.9464664e+01, ..., -1.3099131e+01, -6.3211486e-02,  1.3569843e+00],\n",
       "       [-1.8587533e+00, -2.6162285e+01,  2.5469841e+01, ..., -1.3598913e+00, -1.2668482e+00, -3.8842266e+00],\n",
       "       [ 9.9321854e+01, -1.1406039e+01, -1.6813551e+01, ...,  5.7678995e+00, -1.2250130e+01, -4.2018590e+00]], shape=(124, 90), dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np = train_x.detach().cpu().numpy()\n",
    "X_np = StandardScaler().fit_transform(X_np)\n",
    "X_pca = pca.fit_transform(X_np)\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcd611c-548c-4941-a343-718683e29e39",
   "metadata": {},
   "source": [
    "We can see that 90 PCA components can explain 93% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b55210c2-e094-4b23-a757-ae476d67680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1416 0.2287 0.2929 0.3336 0.3639 0.3925 0.4147 0.4333 0.4496 0.4644 0.4781 0.4908 0.5034 0.5146 0.5256 0.5363 0.5465 0.5565 0.5664 0.5762 0.5854 0.5941 0.6026 0.6107 0.6187 0.6264 0.634  0.6416\n",
      " 0.6491 0.6563 0.6635 0.6706 0.6776 0.6844 0.691  0.6975 0.7038 0.7101 0.7163 0.7224 0.7283 0.7341 0.7398 0.7455 0.7509 0.7564 0.7618 0.767  0.7722 0.7773 0.7823 0.7872 0.792  0.7967 0.8014 0.806\n",
      " 0.8105 0.815  0.8194 0.8238 0.828  0.8322 0.8364 0.8405 0.8445 0.8484 0.8524 0.8562 0.8599 0.8636 0.8673 0.8709 0.8745 0.878  0.8815 0.885  0.8884 0.8917 0.895  0.8982 0.9014 0.9046 0.9077 0.9108\n",
      " 0.9138 0.9168 0.9198 0.9227 0.9255 0.9283]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(pca.explained_variance_ratio_.cumsum(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "297c73fe-ca2b-4320-b1f8-1ba26103a818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=90)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=90)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=90)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8571415b-6fea-46e1-8f53-b4e38dbacfd6",
   "metadata": {},
   "source": [
    "# Train the model using SGD and Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e601106-8cb9-45f9-a096-f969557afc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "\n",
    "bs = 8\n",
    "\n",
    "train_dl = DataLoader(list(zip(train_x, train_y)), batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(list(zip(valid_x, valid_y)), batch_size=bs)\n",
    "\n",
    "# dls = DataLoaders(train_dl, valid_dl)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d3817d1-069c-4c80-81d2-45f7e52d1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37b334-c334-4a16-8e6d-7fe2fa6dba6b",
   "metadata": {},
   "source": [
    "Tumor samples have label y = 1\n",
    "Normal samples have label y = 0. \n",
    "Thus we use the linear model\n",
    "$$z=w^⊤ x+b,$$\n",
    "where the weight $w=(w_1,w_2, \\ldots, w_m)$ has the number of entries which corresponds to the number of probes $m$ and $b$ represents bias. The way that we defined the label, the signs and the absolute value of the weights suggest the following:\n",
    "* $w_i>0$: higher expression pushes toward tumor;\n",
    "* $w_i<0$: higher expression pushes toward normal;\n",
    "* Large $|w_i|$: this probe contributes strongly to the decision direction;\n",
    "* Small $|w_i|$: this probe carries no predictive signal.\n",
    "\n",
    "As we are building a model which can perform a binary classification, i.e., whether a given sample has tumor (value 1) or normal (value 0), we use the nn.BCEWithLogitLoss() loss function. \n",
    "Binary cross-entropy is defined per sample:\n",
    "\n",
    "$$\\ell(x, y)\n",
    "= -\\big[ y \\log p(x) + (1 - y)\\log(1 - p(x)) \\big],$$\n",
    "where $p(x)=P(y=1|x)=\\sigma(w^⊤ x+b)$, and $\\sigma$ is the sigmoid function.\n",
    "And the model objective is the average loss over \n",
    "$N$ elements ($N$ is the batch size.):\n",
    "$$L\n",
    "= \\frac{1}{N} \\sum_{i=1}^{N} \\ell(x_i, y_i)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3257f-6f7f-4703-ad55-780b54674c9f",
   "metadata": {},
   "source": [
    "## Adding nonlinearity to the model\n",
    "We quickly recall nn.Sequential, a container module in PyTorch designed to stack neural network layers in a specific, ordered sequence. \n",
    "```python \\n\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 1)\n",
    ")\n",
    "```\n",
    "Then calling model(x) is equivalent to\n",
    "\n",
    "```python \\n\n",
    "x = nn.Linear(100,50)(x)\n",
    "x = nn.ReLU()(x)\n",
    "x = nn.Linear(50,1)(x)\n",
    "```\n",
    "\n",
    "## Layers and the change of the shape of the input\n",
    "\n",
    "We add Fully-connected layer to improve our model. In particular, we updated the linear model using ```.ReLU()```. We add layers as follows: \n",
    "```python \\n\n",
    "model = nn.Sequential(\n",
    "        nn.Linear(X.shape[1], 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 1)\n",
    "        )\n",
    "```\n",
    "We defined previously train_dl, the dataloader with batch size (bs=32) as follows.\n",
    "```python \\n\n",
    "train_dl = DataLoader(list(zip(train_x, train_y)), batch_size=bs, shuffle=True)\n",
    "```\n",
    "Note that we have 124 pairs in ```train_dl``` with batches of size 32, 32, 32, 28."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0448ca-bbd7-4dee-867c-504cd29715d6",
   "metadata": {},
   "source": [
    "We recall that our baseline is ```y.mean()=0.8387```. Thus the model from ```predictions.ipynb``` cannot improve its accuracy beyond the baseline. Now we make the model deeper to make improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff753727-4391-4cb5-ab46-bc7ddd6146be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8387)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3aa27-7571-48b3-a8d5-8b22eeb10fae",
   "metadata": {},
   "source": [
    "To improve the model, we try adding more layers to the model. On the other hand, as it shows below, overfitting happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7c90c7b-0eb6-4a3a-9af8-3cb1c098474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(preds, y, thresh=0.5):\n",
    "    return ((preds.sigmoid() > thresh) == y).float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0eb3d95f-1b4e-4db2-9df6-6a9ce5e192b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_more_layer(opt, epochs=20):\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(X.shape[1],128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128,64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32,16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16,8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8,4),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4,1)\n",
    "    )  \n",
    "\n",
    "    \n",
    "#   We had previously only the following single layer     \n",
    "#   model = nn.Linear(X.shape[1], 1) \n",
    "#   With the single-layer model, model(xb) is of torch size model(xb).shape=[28,1] and yb is of torch size [28]\n",
    "\n",
    "\n",
    "    # The folloing line nstantiates the optimizer, passing it the model’s trainable parameters\n",
    "    # opt = SGD(model.parameters()) is equivalent to train_model(SGD)\n",
    "    opt = opt(model.parameters())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            # Recall that loss_func = nn.BCEWithLogitsLoss()\n",
    "            \n",
    "            loss = loss_func(model(xb).squeeze(), yb)\n",
    "            loss.backward()\n",
    "            \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            probs = model(valid_x).sigmoid()\n",
    "        \n",
    "        print(f\"Epoch {epoch}: loss={total_loss:.3f}, acc={validate_epoch(model)}\", model(xb).shape)\n",
    "#        print(probs.min().item(), probs.max().item(), probs.mean().item())\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a967595-ffcb-4f50-8f85-d557ed6972b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more layer\n",
      "Epoch 0: loss=5.817, acc=0.7825 torch.Size([4, 1])\n",
      "Epoch 1: loss=1.575, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 2: loss=0.416, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 3: loss=0.042, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 4: loss=0.030, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 5: loss=0.047, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 6: loss=0.043, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 7: loss=0.027, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 8: loss=0.024, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 9: loss=0.017, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 10: loss=0.017, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 11: loss=0.011, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 12: loss=0.012, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 13: loss=0.010, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 14: loss=0.010, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 15: loss=0.009, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 16: loss=0.008, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 17: loss=0.008, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 18: loss=0.006, acc=0.7357 torch.Size([4, 1])\n",
      "Epoch 19: loss=0.008, acc=0.7357 torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"more layer\")\n",
    "model_more_layer = train_model_more_layer(\n",
    "    lambda params: Adam(params, lr=1e-3, weight_decay=1e-3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b79c3-5313-476c-a777-b4d650923f09",
   "metadata": {},
   "source": [
    "# Learning with data filtered by the PCA \n",
    "We use SGD+ReLU (same as above) on the data filtered by the PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf14ce71-c1d0-41ca-adb9-f024be349ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_pca = pca.fit_transform(train_x)   # (124, 85)\n",
    "valid_x_pca = pca.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99e48b82-3b24-42b5-a762-968ba3e48245",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_pca = torch.tensor(train_x_pca, dtype=torch.float32)\n",
    "valid_x_pca = torch.tensor(valid_x_pca, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc5da09a-3f56-47cc-a09a-b2c9d2e27ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([124, 90])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca = torch.tensor(X_pca)\n",
    "# X_pca = X_pca.detach().clone()\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "033d54fb-ae5d-4f45-b3d4-a122f0d1ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=8\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    list(zip(train_x_pca, train_y)),\n",
    "    batch_size=bs,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_dl = DataLoader(\n",
    "    list(zip(valid_x_pca, valid_y)),\n",
    "    batch_size=bs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ec21cf7-3818-4a2a-8e69-a4a833aedd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([124, 90]),\n",
       " torch.Size([31, 90]),\n",
       " torch.Size([124]),\n",
       " torch.Size([31]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_pca.shape, valid_x_pca.shape, train_y.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e7ece7-38e0-4368-a601-91062f908096",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def batch_accuracy_sm(preds, y, thresh=0.5):\n",
    "    # .squeeze() ensures [batch_size, 1] becomes [batch_size]\n",
    "    return ((preds.sigmoid().squeeze() > thresh) == y).float().mean()\n",
    "\n",
    "def validate_epoch_sm(model):\n",
    "    model.eval() # Always set to eval mode for validation\n",
    "    with torch.no_grad(): # Disable gradient calculation\n",
    "        accs = [batch_accuracy_sm(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d320d-811f-4cee-b13f-bda3ab0cbfe6",
   "metadata": {},
   "source": [
    "We make few changes to prevent overconfidence and make the model more stable. First, we smoothen the label. Instead of targets being strictly binary, between 0 and 1, we move them slightly toward the middle (0.5). For a smoothing value of ```eps=0.1```, 0 becomes 0.05 and 1 becomes 0.95. We also added ```nn.Dropout(0.3)``` to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c45362f-3dbc-42cb-a67b-04d8f4c0e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss=1.9600, Acc=0.9375\n",
      "Epoch 1: Loss=0.5031, Acc=1.0000\n",
      "Epoch 2: Loss=0.4371, Acc=1.0000\n",
      "Epoch 3: Loss=0.3993, Acc=0.9688\n",
      "Epoch 4: Loss=0.3865, Acc=1.0000\n",
      "Epoch 5: Loss=0.3549, Acc=1.0000\n",
      "Epoch 6: Loss=0.3817, Acc=1.0000\n",
      "Epoch 7: Loss=0.4335, Acc=1.0000\n",
      "Epoch 8: Loss=0.3029, Acc=0.9688\n",
      "Epoch 9: Loss=0.3434, Acc=0.9688\n",
      "Epoch 10: Loss=0.3297, Acc=0.9688\n",
      "Epoch 11: Loss=0.3481, Acc=1.0000\n",
      "Epoch 12: Loss=0.3178, Acc=1.0000\n",
      "Epoch 13: Loss=0.3101, Acc=1.0000\n",
      "Epoch 14: Loss=0.3055, Acc=1.0000\n",
      "Epoch 15: Loss=0.3057, Acc=1.0000\n",
      "Epoch 16: Loss=0.2920, Acc=1.0000\n",
      "Epoch 17: Loss=0.2777, Acc=1.0000\n",
      "Epoch 18: Loss=0.2930, Acc=1.0000\n",
      "Epoch 19: Loss=0.2922, Acc=1.0000\n"
     ]
    }
   ],
   "source": [
    "def train_model_smoothed(opt, epochs=20, eps=0.1):\n",
    "    \n",
    "    # A shallower model is less likely to \"memorize\" noise in small genomic datasets\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(X_pca.shape[1], 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(128, 1)\n",
    "    )  \n",
    "    \n",
    "    opt = opt(model.parameters())\n",
    "    # Notice: No label_smoothing argument here anymore\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for xb, yb in train_dl:\n",
    "            # --- Manual Label Smoothing Step ---\n",
    "            # Formula: smoothed = y * (1 - eps) + 0.5 * eps\n",
    "            yb_smoothed = yb * (1 - eps) + (0.5 * eps)\n",
    "            \n",
    "            logits = model(xb).squeeze()\n",
    "            loss = loss_func(logits, yb_smoothed)\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        acc = validate_epoch_sm(model)\n",
    "        if epoch % 1 == 0 or epoch == epochs-1:\n",
    "            print(f\"Epoch {epoch}: Loss={total_loss/len(train_dl):.4f}, Acc={acc:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Running with manual smoothing\n",
    "model_smooth = train_model_smoothed(\n",
    "    lambda params: torch.optim.AdamW(params, lr=1e-3, weight_decay=0.1),\n",
    "    eps=0.1  # 10% smoothing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7df5d7-ac33-4cd1-964e-dcb0a59dc433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
